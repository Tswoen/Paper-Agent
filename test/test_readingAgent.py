from src.agents.reading_agent import read_agent
from autogen_agentchat.ui import Console

async def main():
    # 创建一个用户消息
    user_message = """
    [{'paper_id': '2508.21824v1', 'title': 'DriveQA: Passing the Driving Knowledge Test', 'authors': ['Maolin Wei', 'Wanzhou Liu', 'Eshed Ohn-Bar'], 'summary': 'If a Large Language Model (LLM) were to take a driving knowledge test today,\nwould it pass? Beyond standard spatial and visual question-answering (QA) tasks\non current autonomous driving benchmarks, driving knowledge tests require a\ncomplete understanding of all traffic rules, signage, and right-of-way\nprinciples. To pass this test, human drivers must discern various edge cases\nthat rarely appear in real-world datasets. In this work, we present DriveQA, an\nextensive open-source text and vision-based benchmark that exhaustively covers\ntraffic regulations and scenarios. Through our experiments using DriveQA, we\nshow that (1) state-of-the-art LLMs and Multimodal LLMs (MLLMs) perform well on\nbasic traffic rules but exhibit significant weaknesses in numerical reasoning\nand complex right-of-way scenarios, traffic sign variations, and spatial\nlayouts, (2) fine-tuning on DriveQA improves accuracy across multiple\ncategories, particularly in regulatory sign recognition and intersection\ndecision-making, (3) controlled variations in DriveQA-V provide insights into\nmodel sensitivity to environmental factors such as lighting, perspective,\ndistance, and weather conditions, and (4) pretraining on DriveQA enhances\ndownstream driving task performance, leading to improved results on real-world\ndatasets such as nuScenes and BDD, while also demonstrating that models can\ninternalize text and synthetic traffic knowledge to generalize effectively\nacross downstream QA tasks.', 'published': 2025, 'published_date': '2025-08-29T17:59:53+00:00', 'url': 'http://arxiv.org/abs/2508.21824v1', 'pdf_url': 'http://arxiv.org/pdf/2508.21824v1', 'primary_category': 'cs.CV', 'categories': ['cs.CV'], 'doi': None}, {'paper_id': '2508.21810v1', 'title': 'QR-LoRA: QR-Based Low-Rank Adaptation for Efficient Fine-Tuning of Large Language Models', 'authors': ['Jessica Liang', 'Anirudh Bharadwaj'], 'summary': 'The growing scale of Large Language Models (LLMs) has necessitated the\ndevelopment of parameter-efficient fine-tuning techniques. Low-Rank Adaptation\n(LoRA) has emerged as a promising approach, reducing the number of trainable\nparameters by applying low-rank updates to pretrained weights. While standard\nLoRA learns both update factors directly, several recent variants first\ninitialize those matrices via an SVD of the pretrained weights -- an operation\nthat can be expensive on large models and yields singular vectors that are not\nalways easy to interpret. In this work, we extract an orthonormal basis from\nthe pretrained weight matrix using QR decomposition with column pivoting, and\nthen express the LoRA update as a linear combination of these basis vectors --\ntraining only the scalar coefficients, which imposes clear structure on\nadaptation and drastically reduces parameter count. Experiments across GLUE\ntasks show that QR-LoRA matches or exceeds the performance of full fine-tuning,\nstandard LoRA, and SVD-LoRA (LoRA with update matrices initialized via singular\nvalue decomposition) with as few as 601 parameters -- a reduction of over 1000x\ncompared to full fine-tuning and 77x fewer than typical LoRA setups.', 'published': 2025, 'published_date': '2025-08-29T17:47:27+00:00', 'url': 'http://arxiv.org/abs/2508.21810v1', 'pdf_url': 'http://arxiv.org/pdf/2508.21810v1', 'primary_category': 'cs.LG', 'categories': ['cs.LG'], 'doi': None}]
    """

    # 让代理处理用户消息
    await Console(
        read_agent.run_stream(task=user_message)
    )

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
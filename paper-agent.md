# 项目核心定位与命名建议
+ **项目名：** Paper-Agent
+ **项目背景：**设计并落地自动化调研报告生成系统，解决领域论文调研 “耗时长、分析浅” 问题，支撑科研人员快速掌握领域现状。
+ **核心价值：** 不是简单的文献摘要器，而是一个 **“领域研究助理”** ，能自动完成“检索-阅读-分析-综合-报告”的完整工作流，提供有深度、有见解的领域综述报告。

# 项目涉及将分为以下几个模块，并给出每个模块的详细流程：

## 数据获取模块（search_agent）
1.
   定义数据模型 ：使用Pydantic创建了 SearchQuery 类，用于结构化存储搜索条件，包括查询词列表、开始时间和结束时间。
2.
   初始化搜索代理 ：创建了 search_agent 实例，它是一个AssistantAgent，使用专门的搜索模型客户端和系统提示。
3.
   实现搜索逻辑 ：核心是 search_node 异步函数，其工作流程为：

   

   - 从输入状态获取用户请求

   - 将用户请求发送给大语言模型，生成结构化的搜索查询条件

   - 使用 PaperSearcher 服务执行实际的论文搜索

   - 将搜索结果保存到状态中

   - 通过状态队列发送处理进度和结果

   - 异常处理机制确保搜索失败时能提供错误信息

4.
   状态管理 ：通过 ExecutionState 和 BackToFrontData 管理和传递搜索过程中的状态信息，支持前后端通信。

这个模块是论文检索流程的关键组件，负责将用户的自然语言查询转换为精确的搜索条件，并获取相关学术论文结果。



## 阅读与信息结构化提取（reading_agent）
          

`reading_agent.py` 是一个用于学术论文阅读和信息提取的代理模块，主要功能如下：



1. 定义数据模型：使用Pydantic创建了三个数据模型：

   - `KeyMethodology`：表示论文中的关键方法论，包含名称、核心原理和创新点

   - `ExtractedPaperData`：表示从单篇论文中提取的数据，包含核心问题、关键方法、使用的数据集、评估指标、主要结果、局限性和贡献

   - `ExtractedPapersData`：用于包装多篇论文的提取数据列表



2. 初始化阅读代理：创建了`read_agent`实例，它是一个AssistantAgent，使用专门的阅读模型客户端和系统提示。



3. 实现阅读和提取逻辑：核心是`reading_node`异步函数，其工作流程为：

   - 从输入状态获取搜索到的论文列表

   - 使用`asyncio.gather`并行处理所有论文，提高效率

   - 通过`read_agent`对每篇论文进行内容分析和信息提取

   - 合并所有论文的提取结果

   - 将提取的数据转换为结构化格式并存储到向量数据库(ChromaClient)

   - 通过状态队列发送处理进度和结果

   - 异常处理机制确保阅读失败时能提供错误信息



4. 状态管理：通过`ExecutionState`和`BackToFrontData`管理和传递阅读过程中的状态信息，支持前后端通信。



这个模块是论文信息提取流程的关键组件，负责将搜索到的原始论文转换为结构化的关键信息，并存储到向量数据库中以供后续分析使用。



## 数据分析模块（analyse_agent）


这四个文件共同构成了论文分析的核心流程，让我们逐一了解它们的功能：



### 1. analyse_agent.py - 论文分析主协调智能体


这是整个论文分析流程的核心协调器，负责管理和调用其他分析子智能体。主要功能包括：

- 初始化三个关键子智能体：聚类智能体(PaperClusterAgent)、深度分析智能体(DeepAnalyseAgent)和全局分析智能体(GlobalanalyseAgent)

- 定义了处理论文数据的消息处理方法

- 实现了完整的分析流程：先对论文进行聚类，然后并行对每个聚类进行深度分析，最后整合所有结果生成全局分析报告

- 提供`analyse_node`函数作为状态管理的处理节点，负责更新执行状态和结果



### 2. cluster_agent.py - 论文聚类智能体


负责对检索到的论文进行智能聚类，实现了：

- 使用Qwen3-Embedding-8B模型为论文生成嵌入向量

- 应用KMeans算法对论文进行聚类，并通过肘部法则确定最佳聚类数量

- 定义了PaperCluster数据类来存储聚类信息

- 使用LLM为每个聚类自动生成主题描述和关键词

- 提供灵活的响应解析功能，支持多种格式的LLM输出



### 3. deep_analyse_agent.py - 深度分析智能体


对每个论文聚类进行深入的学术分析，功能包括：

- 定义DeepAnalyseResult数据类存储分析结果

- 从四个维度进行分析：技术趋势、方法对比、性能分析和局限性

- 利用LLM生成结构化的分析报告

- 支持并行处理多个聚类



###  4. global_analyse_agent.py - 全局分析智能体


负责整合所有聚类的分析结果，生成综合性分析报告：

- 汇总各聚类的主题、关键词和分析内容

- 从六个维度生成全局分析：技术趋势总结、方法对比、应用领域分析、研究热点识别、局限性总结和建议与展望

- 输出包含总聚类数、总论文数、各聚类主题和完整分析内容的结构化结果



###  整体工作流程


1. 数据输入：系统接收从reading_agent提取的结构化论文数据

2. 聚类分析：cluster_agent对论文进行向量化和聚类，生成主题和关键词

3. 深度分析：deep_analyse_agent并行对每个聚类进行多维度学术分析

4. 全局综合：global_analyse_agent整合所有分析结果，生成最终的全局分析报告

5. 状态管理：整个过程通过analyse_node函数管理执行状态并更新结果



这四个智能体协同工作，形成了一个完整的学术论文智能分析流水线，能够从大量论文中提取结构化信息，进行智能分类，并生成深入的学术分析报告。

## 写作模块
查看写作相关Agent文件的完整内容，以便全面了解它们的功能和工作流程。



下面这些文件共同构成了一个基于LangGraph的智能论文写作系统，负责将用户需求转换为完整的学术论文内容。让我详细介绍每个文件的功能：

### 1. writing_state_models.py - 写作状态数据模型
定义了写作过程中使用的核心数据结构：

+ WritingStage：枚举类型，定义写作流程的不同阶段（初始化、大纲、分节、写作、研究、完成）
+ SectionState：表示单个章节的状态，包含内容和完成状态
+ WritingState：整个写作过程的状态字典，存储用户请求、全局分析、章节列表、已写章节、当前索引和检索资料

### 2. writing_director_agent.py - 写作主管智能体
负责将用户需求分解为具体的写作子任务：

+ 初始化一个AssistantAgent作为写作主管
+ 接收用户请求和全局分析结果
+ 生成结构清晰的写作大纲，并拆分为带编号的小节
+ 提供`parse_outline`函数解析LLM输出，提取小节列表
+ 通过`writing_director_node`函数返回拆分后的写作小节列表

### 3. retrieval_agent.py - 检索助手智能体
负责为写作提供相关资料支持：

+ 初始化检索智能体和检索工具
+ 提供`parse_to_list`函数从文本中提取查询列表
+ 通过`retrieval_node`函数执行资料检索，支持并行查询
+ 对检索结果进行去重处理，确保资料质量

### 4. writing_agent.py (子模块) - 章节写作智能体
负责具体章节内容的生成：

+ 初始化写作助手智能体
+ 提供`section_writing_node`函数处理单个章节的写作
+ 根据当前小节索引、全局分析和检索资料生成内容
+ 管理章节的完成状态，标记已完成的章节

### 5. writing_agent.py (主模块) - 写作工作流管理
构建并管理整个写作流程：

+ 定义`condition_edge`函数决定工作流的执行路径
+ 创建`WritingWorkflow`类，使用LangGraph构建状态机工作流
+ 集成写作主管、检索和写作三个核心节点
+ 提供`writing_node`函数作为系统入口，管理全局状态
+ 处理执行过程中的异常情况，更新执行状态

### 整体工作流程
1. 初始化阶段：`writing_node`函数接收用户请求和全局分析结果，创建写作状态
2. 任务分解：`writing_director_node`生成并拆分写作大纲为具体小节
3. 章节写作：`section_writing_node`逐个处理小节，生成初步内容
4. 资料检索：根据需要，`retrieval_node`检索相关资料辅助写作
5. 循环迭代：通过条件边控制，在检索和写作之间循环，直到所有章节完成
6. 结果输出：完成所有章节后，输出完整的写作结果

这个系统通过智能体协作和状态管理，实现了从用户需求到完整论文的自动化写作过程，支持检索增强写作和多轮迭代完善。

## 报告生成模块
`report_agent.py` 文件实现了一个报告生成智能代理，负责将分散的章节内容组装成一份完整的学术调研报告。以下是其主要功能：

### 核心功能
1. 初始化报告智能代理：创建了一个名为 `report_agent` 的 AssistantAgent 实例，配置了专门的报告生成模型客户端和系统提示词
2. 提供报告生成节点：实现了 `report_node` 异步函数作为整个论文处理流程中的报告生成环节
3. 状态管理：
    - 更新当前执行状态为 REPORTING
    - 向状态队列发送处理中、完成或错误的状态信息
4. 报告组装流程：
    - 收集已完成的写作章节
    - 将章节内容合并为文本串
    - 构建提示词，要求将章节内容组装成完整的 Markdown 格式调研报告
    - 调用 LLM 生成最终报告
    - 保存生成的报告到当前状态中
5. 异常处理：捕获并处理生成过程中的错误，记录错误信息并更新状态

### 工作流程
1. 接收来自写作阶段的章节内容
2. 将章节内容合并并发送给 LLM
3. 要求 LLM 以 Markdown 格式重新组织内容，添加必要的过渡语句
4. 获取并保存生成的完整报告
5. 更新全局状态并通知前端

这个组件是整个论文生成流水线的最后一环，负责将零散的章节内容整合为一份结构完整、逻辑连贯的最终调研报告，确保输出符合学术风格和格式要求。



## 主控协调模块
`orchestrator.py`文件是Paper-Agent系统的核心协调模块，主要负责构建和管理基于LangGraph的完整工作流，协调各个智能体完成学术论文相关任务。

该文件实现了以下关键功能：

1. 定义了`PaperAgentOrchestrator`类，通过`_build_graph`方法构建LangGraph工作流
2. 集成了五个核心智能体节点：搜索节点(search_node)、阅读节点(reading_node)、分析节点(analyse_node)、写作节点(writing_node)和报告节点(report_node)
3. 实现了错误处理机制，通过`handle_error_node`方法处理工作流中的异常情况
4. 通过`condition_handler`方法定义工作流的条件跳转逻辑，根据当前状态和错误信息决定下一个执行节点
5. 提供`run`方法执行完整工作流，接收用户请求和最大论文数量参数，初始化状态并调用LangGraph工作流

该模块是整个系统的中枢神经，将各个独立的智能体整合为一个完整的流水线，实现从用户查询到最终报告生成的端到端流程管理。